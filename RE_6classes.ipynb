{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztgOp6u2TZa2",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 8.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 102.0
    },
    "outputId": "f041f6f5-a7f2-4468-86b1-7954b962924f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521363070209E12,
     "user_tz": -480.0,
     "elapsed": 6036.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/AlwaysSomeone/RE_6classes.git ./test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yy46NH4HTyet",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 3.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 170.0
    },
    "outputId": "2067ba77-12cc-4937-9355-f1638ddc0f8b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521363147505E12,
     "user_tz": -480.0,
     "elapsed": 2117.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading word embedding data...\n",
      "reading relation to id\n",
      "reading train data...\n",
      "reading test data ...\n",
      "organizing train data\n",
      "organizing test data\n",
      "reading training data\n",
      "seprating train data\n",
      "seperating test all data\n"
     ]
    }
   ],
   "source": [
    "!python initial.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "T8IRqZr4T2br",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 19.0
      },
      {
       "item_id": 38.0
      },
      {
       "item_id": 62.0
      },
      {
       "item_id": 90.0
      },
      {
       "item_id": 104.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 4508.0
    },
    "outputId": "d202dbd8-1222-4159-a8f5-7353b186c7ae",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521363272439E12,
     "user_tz": -480.0,
     "elapsed": 107682.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
      "  from ._conv import register_converters as _register_converters\n",
      "main函数开始执行2018-03-18T08:52:14.954232\n",
      "reading wordembedding\n",
      "reading training data\n",
      "2018-03-18 08:52:15.095714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-03-18 08:52:15.096293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.11GiB\n",
      "2018-03-18 08:52:15.096362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n",
      "2018-03-18 08:52:15.362539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10774 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2018-03-18T08:52:15.537100\n",
      "WARNING:tensorflow:From /content/network.py:132: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "2018-03-18T08:52:21.854677\n",
      "2018-03-18T08:52:49.826115: step 1, softmax_loss 96.6773, acc 0.08\n",
      "2018-03-18T08:52:50.171676: step 2, softmax_loss 95.0043, acc 0.16\n",
      "2018-03-18T08:52:50.344683: step 3, softmax_loss 91.5628, acc 0.34\n",
      "2018-03-18T08:52:50.517590: step 4, softmax_loss 93.7986, acc 0.28\n",
      "2018-03-18T08:52:50.684370: step 5, softmax_loss 91.5143, acc 0.3\n",
      "2018-03-18T08:52:50.842867: step 6, softmax_loss 89.8667, acc 0.26\n",
      "2018-03-18T08:52:50.998533: step 7, softmax_loss 86.188, acc 0.3\n",
      "2018-03-18T08:52:51.152629: step 8, softmax_loss 86.1499, acc 0.32\n",
      "2018-03-18T08:52:51.306185: step 9, softmax_loss 87.5234, acc 0.26\n",
      "2018-03-18T08:52:51.461706: step 10, softmax_loss 86.8789, acc 0.24\n",
      "2018-03-18T08:52:51.608712: step 11, softmax_loss 82.7256, acc 0.28\n",
      "2018-03-18T08:52:51.762306: step 12, softmax_loss 82.8885, acc 0.34\n",
      "2018-03-18T08:52:51.913751: step 13, softmax_loss 86.0494, acc 0.16\n",
      "2018-03-18T08:52:52.063827: step 14, softmax_loss 80.4838, acc 0.28\n",
      "2018-03-18T08:52:52.224072: step 15, softmax_loss 79.4801, acc 0.26\n",
      "2018-03-18T08:52:52.380274: step 16, softmax_loss 83.0987, acc 0.36\n",
      "2018-03-18T08:52:52.534967: step 17, softmax_loss 81.7126, acc 0.5\n",
      "2018-03-18T08:52:52.692334: step 18, softmax_loss 78.135, acc 0.42\n",
      "2018-03-18T08:52:52.847306: step 19, softmax_loss 80.0379, acc 0.42\n",
      "2018-03-18T08:52:53.001575: step 20, softmax_loss 80.3698, acc 0.36\n",
      "2018-03-18T08:52:53.157056: step 21, softmax_loss 80.9609, acc 0.42\n",
      "2018-03-18T08:52:53.309366: step 22, softmax_loss 73.4813, acc 0.44\n",
      "2018-03-18T08:52:53.465233: step 23, softmax_loss 75.6513, acc 0.4\n",
      "2018-03-18T08:52:53.630120: step 24, softmax_loss 74.5568, acc 0.52\n",
      "2018-03-18T08:52:53.782780: step 25, softmax_loss 72.7842, acc 0.44\n",
      "2018-03-18T08:52:53.930980: step 26, softmax_loss 70.5245, acc 0.56\n",
      "2018-03-18T08:52:54.095361: step 27, softmax_loss 60.8554, acc 0.6\n",
      "2018-03-18T08:52:54.250308: step 28, softmax_loss 71.1553, acc 0.44\n",
      "2018-03-18T08:52:54.401350: step 29, softmax_loss 68.216, acc 0.56\n",
      "2018-03-18T08:52:54.556637: step 30, softmax_loss 57.7168, acc 0.52\n",
      "2018-03-18T08:52:54.710150: step 31, softmax_loss 61.9684, acc 0.58\n",
      "2018-03-18T08:52:54.863322: step 32, softmax_loss 52.8719, acc 0.56\n",
      "2018-03-18T08:52:55.024509: step 33, softmax_loss 50.4842, acc 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-18T08:52:55.175332: step 34, softmax_loss 59.0714, acc 0.66\n",
      "2018-03-18T08:52:55.328936: step 35, softmax_loss 53.8459, acc 0.74\n",
      "2018-03-18T08:52:55.481145: step 36, softmax_loss 59.0331, acc 0.72\n",
      "2018-03-18T08:52:55.633565: step 37, softmax_loss 59.3943, acc 0.62\n",
      "2018-03-18T08:52:55.786116: step 38, softmax_loss 52.2787, acc 0.68\n",
      "2018-03-18T08:52:55.940961: step 39, softmax_loss 62.2973, acc 0.54\n",
      "2018-03-18T08:52:56.095140: step 40, softmax_loss 55.8695, acc 0.66\n",
      "2018-03-18T08:52:56.251700: step 41, softmax_loss 49.3798, acc 0.64\n",
      "2018-03-18T08:52:56.404541: step 42, softmax_loss 44.8658, acc 0.7\n",
      "2018-03-18T08:52:56.561274: step 43, softmax_loss 43.9358, acc 0.74\n",
      "2018-03-18T08:52:56.720920: step 44, softmax_loss 46.8293, acc 0.72\n",
      "2018-03-18T08:52:56.873980: step 45, softmax_loss 45.2472, acc 0.74\n",
      "2018-03-18T08:52:57.023669: step 46, softmax_loss 49.5339, acc 0.64\n",
      "2018-03-18T08:52:57.179283: step 47, softmax_loss 49.183, acc 0.64\n",
      "2018-03-18T08:52:57.331950: step 48, softmax_loss 48.5462, acc 0.66\n",
      "2018-03-18T08:52:57.483307: step 49, softmax_loss 40.1293, acc 0.72\n",
      "2018-03-18T08:52:57.635579: step 50, softmax_loss 37.4391, acc 0.82\n",
      "2018-03-18T08:52:57.790881: step 51, softmax_loss 35.0749, acc 0.78\n",
      "2018-03-18T08:52:57.939140: step 52, softmax_loss 40.9321, acc 0.7\n",
      "2018-03-18T08:52:58.095564: step 53, softmax_loss 41.4449, acc 0.72\n",
      "2018-03-18T08:52:58.244472: step 54, softmax_loss 33.0181, acc 0.82\n",
      "2018-03-18T08:52:58.392083: step 55, softmax_loss 30.0776, acc 0.88\n",
      "2018-03-18T08:52:58.545123: step 56, softmax_loss 44.7795, acc 0.76\n",
      "2018-03-18T08:52:58.696432: step 57, softmax_loss 35.6462, acc 0.78\n",
      "2018-03-18T08:52:58.853495: step 58, softmax_loss 37.2321, acc 0.74\n",
      "2018-03-18T08:52:59.015468: step 59, softmax_loss 36.3816, acc 0.72\n",
      "2018-03-18T08:52:59.166985: step 60, softmax_loss 31.5478, acc 0.84\n",
      "2018-03-18T08:52:59.320080: step 61, softmax_loss 37.3744, acc 0.78\n",
      "2018-03-18T08:52:59.476313: step 62, softmax_loss 41.2463, acc 0.72\n",
      "2018-03-18T08:52:59.631949: step 63, softmax_loss 25.0663, acc 0.88\n",
      "2018-03-18T08:52:59.782426: step 64, softmax_loss 24.3939, acc 0.84\n",
      "2018-03-18T08:52:59.938485: step 65, softmax_loss 24.6693, acc 0.8\n",
      "2018-03-18T08:53:00.092398: step 66, softmax_loss 25.4061, acc 0.82\n",
      "2018-03-18T08:53:00.242135: step 67, softmax_loss 27.2068, acc 0.78\n",
      "2018-03-18T08:53:00.392305: step 68, softmax_loss 35.8397, acc 0.74\n",
      "2018-03-18T08:53:00.545366: step 69, softmax_loss 26.4204, acc 0.84\n",
      "2018-03-18T08:53:00.697527: step 70, softmax_loss 40.2876, acc 0.68\n",
      "2018-03-18T08:53:00.861158: step 71, softmax_loss 29.829, acc 0.72\n",
      "2018-03-18T08:53:01.012426: step 72, softmax_loss 42.2931, acc 0.74\n",
      "2018-03-18T08:53:01.163776: step 73, softmax_loss 21.1867, acc 0.84\n",
      "2018-03-18T08:53:01.321259: step 74, softmax_loss 27.298, acc 0.78\n",
      "2018-03-18T08:53:01.473528: step 75, softmax_loss 40.6102, acc 0.64\n",
      "2018-03-18T08:53:01.625265: step 76, softmax_loss 31.8222, acc 0.8\n",
      "2018-03-18T08:53:01.781766: step 77, softmax_loss 28.8123, acc 0.84\n",
      "2018-03-18T08:53:01.932884: step 78, softmax_loss 28.2384, acc 0.86\n",
      "2018-03-18T08:53:02.085505: step 79, softmax_loss 34.3026, acc 0.76\n",
      "2018-03-18T08:53:02.241121: step 80, softmax_loss 21.3534, acc 0.86\n",
      "2018-03-18T08:53:02.392653: step 81, softmax_loss 20.91, acc 0.88\n",
      "2018-03-18T08:53:02.542896: step 82, softmax_loss 25.0066, acc 0.86\n",
      "2018-03-18T08:53:02.701532: step 83, softmax_loss 34.1292, acc 0.78\n",
      "2018-03-18T08:53:02.853183: step 84, softmax_loss 26.9596, acc 0.8\n",
      "2018-03-18T08:53:03.008676: step 85, softmax_loss 24.307, acc 0.84\n",
      "2018-03-18T08:53:03.156620: step 86, softmax_loss 27.0463, acc 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-18T08:53:03.307758: step 87, softmax_loss 21.1787, acc 0.86\n",
      "2018-03-18T08:53:03.460852: step 88, softmax_loss 30.3429, acc 0.76\n",
      "2018-03-18T08:53:03.617657: step 89, softmax_loss 28.4076, acc 0.82\n",
      "2018-03-18T08:53:03.772163: step 90, softmax_loss 28.8818, acc 0.84\n",
      "2018-03-18T08:53:03.927063: step 91, softmax_loss 25.8021, acc 0.78\n",
      "2018-03-18T08:53:04.084620: step 92, softmax_loss 27.325, acc 0.84\n",
      "2018-03-18T08:53:04.233595: step 93, softmax_loss 18.6136, acc 0.9\n",
      "2018-03-18T08:53:04.384743: step 94, softmax_loss 26.4179, acc 0.86\n",
      "2018-03-18T08:53:04.536059: step 95, softmax_loss 21.0028, acc 0.86\n",
      "2018-03-18T08:53:04.688896: step 96, softmax_loss 23.9583, acc 0.86\n",
      "2018-03-18T08:53:04.845559: step 97, softmax_loss 17.2745, acc 0.9\n",
      "2018-03-18T08:53:04.996993: step 98, softmax_loss 24.5396, acc 0.82\n",
      "2018-03-18T08:53:05.142538: step 99, softmax_loss 23.4478, acc 0.88\n",
      "2018-03-18T08:53:05.296851: step 100, softmax_loss 35.8868, acc 0.78\n",
      "2018-03-18T08:53:05.446806: step 101, softmax_loss 16.4638, acc 0.88\n",
      "2018-03-18T08:53:05.597546: step 102, softmax_loss 16.4957, acc 0.92\n",
      "2018-03-18T08:53:05.747278: step 103, softmax_loss 21.4161, acc 0.86\n",
      "2018-03-18T08:53:05.897904: step 104, softmax_loss 25.8366, acc 0.8\n",
      "2018-03-18T08:53:06.046316: step 105, softmax_loss 14.0464, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-105\n",
      "2018-03-18T08:53:08.238817: step 106, softmax_loss 18.3803, acc 0.9\n",
      "2018-03-18T08:53:08.389955: step 107, softmax_loss 27.4271, acc 0.82\n",
      "2018-03-18T08:53:08.540177: step 108, softmax_loss 12.6087, acc 0.9\n",
      "2018-03-18T08:53:08.697032: step 109, softmax_loss 18.2949, acc 0.84\n",
      "2018-03-18T08:53:08.848186: step 110, softmax_loss 19.898, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-110\n",
      "2018-03-18T08:53:11.086138: step 111, softmax_loss 23.5783, acc 0.84\n",
      "2018-03-18T08:53:11.233402: step 112, softmax_loss 17.709, acc 0.92\n",
      "2018-03-18T08:53:11.383941: step 113, softmax_loss 18.4162, acc 0.92\n",
      "2018-03-18T08:53:11.540220: step 114, softmax_loss 20.9126, acc 0.9\n",
      "2018-03-18T08:53:11.685094: step 115, softmax_loss 26.0728, acc 0.82\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-115\n",
      "2018-03-18T08:53:13.682352: step 116, softmax_loss 33.5503, acc 0.78\n",
      "2018-03-18T08:53:13.834184: step 117, softmax_loss 19.2051, acc 0.86\n",
      "2018-03-18T08:53:13.981140: step 118, softmax_loss 19.49, acc 0.86\n",
      "2018-03-18T08:53:14.136478: step 119, softmax_loss 15.1537, acc 0.92\n",
      "2018-03-18T08:53:14.285001: step 120, softmax_loss 17.984, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-120\n",
      "2018-03-18T08:53:16.275879: step 121, softmax_loss 17.5543, acc 0.92\n",
      "2018-03-18T08:53:16.421704: step 122, softmax_loss 13.2378, acc 0.94\n",
      "2018-03-18T08:53:16.571713: step 123, softmax_loss 16.4353, acc 0.92\n",
      "2018-03-18T08:53:16.725179: step 124, softmax_loss 23.5348, acc 0.78\n",
      "2018-03-18T08:53:16.872706: step 125, softmax_loss 17.1023, acc 0.94\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-125\n",
      "2018-03-18T08:53:18.852564: step 126, softmax_loss 18.6374, acc 0.86\n",
      "2018-03-18T08:53:19.004123: step 127, softmax_loss 12.3126, acc 0.9\n",
      "2018-03-18T08:53:19.148759: step 128, softmax_loss 23.4644, acc 0.82\n",
      "2018-03-18T08:53:19.301363: step 129, softmax_loss 19.6231, acc 0.9\n",
      "2018-03-18T08:53:19.450313: step 130, softmax_loss 25.1472, acc 0.76\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-130\n",
      "2018-03-18T08:53:21.446996: step 131, softmax_loss 18.2411, acc 0.9\n",
      "2018-03-18T08:53:21.589145: step 132, softmax_loss 14.8161, acc 0.92\n",
      "2018-03-18T08:53:21.732220: step 133, softmax_loss 12.5708, acc 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-18T08:53:21.886764: step 134, softmax_loss 24.6324, acc 0.84\n",
      "2018-03-18T08:53:22.031790: step 135, softmax_loss 16.2661, acc 0.94\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-135\n",
      "2018-03-18T08:53:24.088120: step 136, softmax_loss 18.1029, acc 0.84\n",
      "2018-03-18T08:53:24.235931: step 137, softmax_loss 21.8733, acc 0.88\n",
      "2018-03-18T08:53:24.381719: step 138, softmax_loss 7.91295, acc 0.96\n",
      "2018-03-18T08:53:24.535267: step 139, softmax_loss 13.1756, acc 0.94\n",
      "2018-03-18T08:53:24.682680: step 140, softmax_loss 16.4143, acc 0.92\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-140\n",
      "2018-03-18T08:53:26.675950: step 141, softmax_loss 16.3498, acc 0.92\n",
      "2018-03-18T08:53:26.825339: step 142, softmax_loss 11.9936, acc 0.92\n",
      "2018-03-18T08:53:26.975446: step 143, softmax_loss 19.8525, acc 0.82\n",
      "2018-03-18T08:53:27.125044: step 144, softmax_loss 17.1436, acc 0.86\n",
      "2018-03-18T08:53:27.277561: step 145, softmax_loss 17.3962, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-145\n",
      "2018-03-18T08:53:29.310078: step 146, softmax_loss 5.92776, acc 0.98\n",
      "2018-03-18T08:53:29.458615: step 147, softmax_loss 15.7539, acc 0.92\n",
      "2018-03-18T08:53:29.611811: step 148, softmax_loss 12.9377, acc 0.96\n",
      "2018-03-18T08:53:29.767374: step 149, softmax_loss 11.7002, acc 0.9\n",
      "2018-03-18T08:53:29.911486: step 150, softmax_loss 13.3051, acc 0.92\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-150\n",
      "2018-03-18T08:53:31.907634: step 151, softmax_loss 13.0032, acc 0.92\n",
      "2018-03-18T08:53:32.046367: step 152, softmax_loss 18.8591, acc 0.92\n",
      "2018-03-18T08:53:32.192499: step 153, softmax_loss 16.6279, acc 0.88\n",
      "2018-03-18T08:53:32.337003: step 154, softmax_loss 5.35057, acc 0.98\n",
      "2018-03-18T08:53:32.483724: step 155, softmax_loss 15.4493, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-155\n",
      "2018-03-18T08:53:34.494550: step 156, softmax_loss 23.3934, acc 0.82\n",
      "2018-03-18T08:53:34.641509: step 157, softmax_loss 8.04649, acc 0.96\n",
      "2018-03-18T08:53:34.793076: step 158, softmax_loss 16.2952, acc 0.88\n",
      "2018-03-18T08:53:34.950301: step 159, softmax_loss 14.1828, acc 0.88\n",
      "2018-03-18T08:53:35.101550: step 160, softmax_loss 7.33124, acc 0.98\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-160\n",
      "2018-03-18T08:53:37.399266: step 161, softmax_loss 9.46289, acc 0.94\n",
      "2018-03-18T08:53:37.554300: step 162, softmax_loss 14.7388, acc 0.9\n",
      "2018-03-18T08:53:37.708477: step 163, softmax_loss 12.0603, acc 0.92\n",
      "2018-03-18T08:53:37.866415: step 164, softmax_loss 15.6491, acc 0.88\n",
      "2018-03-18T08:53:38.015844: step 165, softmax_loss 6.55473, acc 0.94\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-165\n",
      "2018-03-18T08:53:40.050408: step 166, softmax_loss 15.0808, acc 0.88\n",
      "2018-03-18T08:53:40.198873: step 167, softmax_loss 10.0546, acc 0.92\n",
      "2018-03-18T08:53:40.354023: step 168, softmax_loss 12.3765, acc 0.9\n",
      "2018-03-18T08:53:40.519877: step 169, softmax_loss 13.677, acc 0.88\n",
      "2018-03-18T08:53:40.672308: step 170, softmax_loss 9.17002, acc 0.96\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-170\n",
      "2018-03-18T08:53:42.700785: step 171, softmax_loss 7.59215, acc 0.96\n",
      "2018-03-18T08:53:42.853839: step 172, softmax_loss 10.5421, acc 0.94\n",
      "2018-03-18T08:53:43.009065: step 173, softmax_loss 7.23845, acc 0.96\n",
      "2018-03-18T08:53:43.160514: step 174, softmax_loss 16.5938, acc 0.9\n",
      "2018-03-18T08:53:43.316599: step 175, softmax_loss 24.1652, acc 0.86\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-175\n",
      "2018-03-18T08:53:45.346129: step 176, softmax_loss 19.2932, acc 0.88\n",
      "2018-03-18T08:53:45.498951: step 177, softmax_loss 7.27013, acc 0.92\n",
      "2018-03-18T08:53:45.654487: step 178, softmax_loss 7.2867, acc 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-18T08:53:45.808926: step 179, softmax_loss 10.1019, acc 0.96\n",
      "2018-03-18T08:53:45.961467: step 180, softmax_loss 13.2559, acc 0.9\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-180\n",
      "2018-03-18T08:53:47.984410: step 181, softmax_loss 9.19953, acc 0.96\n",
      "2018-03-18T08:53:48.133872: step 182, softmax_loss 6.20494, acc 0.96\n",
      "2018-03-18T08:53:48.280434: step 183, softmax_loss 7.96609, acc 0.96\n",
      "2018-03-18T08:53:48.431794: step 184, softmax_loss 12.2643, acc 0.92\n",
      "2018-03-18T08:53:48.584501: step 185, softmax_loss 11.1195, acc 0.96\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-185\n",
      "2018-03-18T08:53:50.642652: step 186, softmax_loss 11.8368, acc 0.92\n",
      "2018-03-18T08:53:50.792719: step 187, softmax_loss 9.6324, acc 0.94\n",
      "2018-03-18T08:53:50.938841: step 188, softmax_loss 8.32178, acc 0.96\n",
      "2018-03-18T08:53:51.095491: step 189, softmax_loss 14.1322, acc 0.9\n",
      "2018-03-18T08:53:51.244675: step 190, softmax_loss 7.28583, acc 0.96\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-190\n",
      "2018-03-18T08:53:53.275979: step 191, softmax_loss 12.8884, acc 0.92\n",
      "2018-03-18T08:53:53.426578: step 192, softmax_loss 10.4324, acc 0.92\n",
      "2018-03-18T08:53:53.570644: step 193, softmax_loss 14.0224, acc 0.92\n",
      "2018-03-18T08:53:53.731555: step 194, softmax_loss 10.1745, acc 0.9\n",
      "2018-03-18T08:53:53.880483: step 195, softmax_loss 20.5243, acc 0.88\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-195\n",
      "2018-03-18T08:53:55.919061: step 196, softmax_loss 19.3328, acc 0.84\n",
      "2018-03-18T08:53:56.071935: step 197, softmax_loss 7.18779, acc 0.96\n",
      "2018-03-18T08:53:56.222410: step 198, softmax_loss 8.57666, acc 0.92\n",
      "2018-03-18T08:53:56.375111: step 199, softmax_loss 8.12748, acc 0.94\n",
      "2018-03-18T08:53:56.522478: step 200, softmax_loss 12.268, acc 0.92\n",
      "saving model\n",
      "have saved model to ./model/ATT_GRU_model-200\n",
      "2018-03-18T08:53:58.406621\n"
     ]
    }
   ],
   "source": [
    "!python train_GRU.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pfWPFYryUWh_",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 26.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 1686.0
    },
    "outputId": "6c7bb5fc-237e-486a-9170-68f2f5dd4a4e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.521363331324E12,
     "user_tz": -480.0,
     "elapsed": 39481.0,
     "user": {
      "displayName": "吴小翔",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115671095488650849178"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-03-18 08:54:21.553265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-03-18 08:54:21.553796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.11GiB\n",
      "2018-03-18 08:54:21.553820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n",
      "2018-03-18 08:54:21.811703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10774 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "WARNING:tensorflow:From /content/network.py:132: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "105次训练结果\n",
      "准确率0.7919999969005584\n",
      "saving all test result...\n",
      "PR curve area:0.8237035395776978\n",
      "110次训练结果\n",
      "准确率0.7599999952316284\n",
      "saving all test result...\n",
      "PR curve area:0.8257010523344178\n",
      "115次训练结果\n",
      "准确率0.7839999973773957\n",
      "saving all test result...\n",
      "PR curve area:0.8362934930224198\n",
      "120次训练结果\n",
      "准确率0.8\n",
      "saving all test result...\n",
      "PR curve area:0.8656393426174065\n",
      "125次训练结果\n",
      "准确率0.7719999921321868\n",
      "saving all test result...\n",
      "PR curve area:0.8297942617739213\n",
      "130次训练结果\n",
      "准确率0.7840000009536743\n",
      "saving all test result...\n",
      "PR curve area:0.8607761214080851\n",
      "135次训练结果\n",
      "准确率0.7959999966621399\n",
      "saving all test result...\n",
      "PR curve area:0.870943893164433\n",
      "140次训练结果\n",
      "准确率0.7759999954700469\n",
      "saving all test result...\n",
      "PR curve area:0.8142192142959657\n",
      "145次训练结果\n",
      "准确率0.7839999985694885\n",
      "saving all test result...\n",
      "PR curve area:0.8570231064107423\n",
      "150次训练结果\n",
      "准确率0.7879999971389771\n",
      "saving all test result...\n",
      "PR curve area:0.8705518608286176\n",
      "155次训练结果\n",
      "准确率0.7599999958276749\n",
      "saving all test result...\n",
      "PR curve area:0.839439560063326\n",
      "160次训练结果\n",
      "准确率0.7999999964237213\n",
      "saving all test result...\n",
      "PR curve area:0.8510041287839467\n",
      "165次训练结果\n",
      "准确率0.7599999964237213\n",
      "saving all test result...\n",
      "PR curve area:0.862455519397298\n",
      "170次训练结果\n",
      "准确率0.7999999928474426\n",
      "saving all test result...\n",
      "PR curve area:0.8522248523195791\n",
      "175次训练结果\n",
      "准确率0.7919999957084656\n",
      "saving all test result...\n",
      "PR curve area:0.857514187594225\n",
      "180次训练结果\n",
      "准确率0.8039999985694886\n",
      "saving all test result...\n",
      "PR curve area:0.88188236196725\n",
      "185次训练结果\n",
      "准确率0.7999999952316285\n",
      "saving all test result...\n",
      "PR curve area:0.8622869991356517\n",
      "190次训练结果\n",
      "准确率0.8199999976158142\n",
      "saving all test result...\n",
      "PR curve area:0.8711600311238415\n",
      "195次训练结果\n",
      "准确率0.7919999957084656\n",
      "saving all test result...\n",
      "PR curve area:0.8450412367897482\n",
      "200次训练结果\n",
      "准确率0.7999999952316285\n",
      "saving all test result...\n",
      "PR curve area:0.8791772470404556\n"
     ]
    }
   ],
   "source": [
    "!python evaluation.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RE_6classes.ipynb",
   "version": "0.3.2",
   "views": {},
   "default_view": {},
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
